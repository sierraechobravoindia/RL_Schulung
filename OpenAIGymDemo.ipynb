{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAIGymDemo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNV/ZmZbBOlBV6cz9F/nHEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sierraechobravoindia/RL_Schulung/blob/main/OpenAIGymDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se91W1gW9h54"
      },
      "source": [
        "#Demo Open AI Gym\n",
        "\n",
        "In diesem Notebook soll kurz das RL Framework Open AI Gym und die Interaktion sowie eine Standard-Architektur mit Agenten vorgestellt werden.\n",
        "\n",
        "Homepage des Frameworks:\n",
        "\n",
        "[Open AI Gym](https://gym.openai.com)\n",
        "\n",
        "Übersicht der Environments des Frameworks:\n",
        "\n",
        "[Gym Environments](https://gym.openai.com/envs/#classic_control)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRA2Qt6HFwYR"
      },
      "source": [
        "import gym\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YeNJLQC_J4e"
      },
      "source": [
        "Die folgenden drei Code-Zellen werden nur gebraucht, um das Rendering in Google Colab zu ermöglichen, bei lokaler Installation geht es auch ohne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePJ1GbCxqzZ4"
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "WQICxuczq3fl",
        "outputId": "f99d284e-5a7a-4e70-e642-1685c8b2f357"
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/78/56aa1b5f4d8ac548755ae767d84f0be54fdd9d404197a3d9e4659d272348/setuptools-57.0.0-py3-none-any.whl (821kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 3.0MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 56.1.0\n",
            "    Uninstalling setuptools-56.1.0:\n",
            "      Successfully uninstalled setuptools-56.1.0\n",
            "Successfully installed setuptools-57.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUIqBnVLqXCK"
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqJSwWk-qsPl"
      },
      "source": [
        "#env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
        "env = wrap_env(gym.make(\"CartPole-v1\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2dBZxokGI_X",
        "outputId": "6e72ad10-2922-44d2-d668-08f93e4b4a2b"
      },
      "source": [
        "print(\"Observation Space: \", env.observation_space)\n",
        "print(\"Action Space: \", env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Space:  Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
            "Action Space:  Discrete(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2JkRnLnGUjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "0e2228f3-f6a0-4f2a-aef3-6274f5e0cebd"
      },
      "source": [
        "state = env.reset()\n",
        "\n",
        "while True:\n",
        "\n",
        "  action = env.action_space.sample()\n",
        "  state, reward, done, info = env.step(action)\n",
        "  env.render()\n",
        "  if done:\n",
        "    break;\n",
        "    env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3gB1EHuMeUZ"
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, env):\n",
        "        self.action_size = env.action_space.n\n",
        "        print(\"Action size:\", self.action_size)\n",
        "        \n",
        "    def get_action(self, state):\n",
        "        #action = random.choice(range(self.action_size))\n",
        "        pole_angle = state[2]\n",
        "        action = 0 if pole_angle < 0 else 1\n",
        "        return action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "e4o_iFmcMiL5",
        "outputId": "207b5302-b661-41fe-f571-bfec8367089d"
      },
      "source": [
        "agent = Agent(env)\n",
        "state = env.reset()\n",
        "cnt = 0\n",
        "print(cnt)\n",
        "while True:\n",
        "    action = agent.get_action(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "    cnt += 1\n",
        "\n",
        "    if done:\n",
        "      break\n",
        "\n",
        "print(cnt)   \n",
        "env.close()\n",
        "show_video()    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action size: 2\n",
            "0\n",
            "25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngsyH4WT9gT4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft9KcDD4JDrx",
        "outputId": "8a3ef0c3-6957-42b3-ac23-7cbd2b797eff"
      },
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "from collections import deque\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior() \n",
        "\n",
        "print(\"Gym:\", gym.__version__)\n",
        "print(\"Tensorflow:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Gym: 0.17.3\n",
            "Tensorflow: 2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MrDowOcJJGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c213cefd-9166-49f1-e77c-d38ea70aaa7a"
      },
      "source": [
        "env_name = \"CartPole-v0\"\n",
        "env = wrap_env(gym.make(env_name))\n",
        "print(\"Observation space:\", env.observation_space)\n",
        "print(\"Action space:\", env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
            "Action space: Discrete(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFiSNavSJVqK"
      },
      "source": [
        "class QNetwork():\n",
        "    def __init__(self, state_dim, action_size):\n",
        "        self.state_in = tf.placeholder(tf.float32, shape=[None, *state_dim])\n",
        "        self.action_in = tf.placeholder(tf.int32, shape=[None])\n",
        "        self.q_target_in = tf.placeholder(tf.float32, shape=[None])\n",
        "        action_one_hot = tf.one_hot(self.action_in, depth=action_size)\n",
        "        \n",
        "        self.hidden1 = tf.layers.dense(self.state_in, 100, activation=tf.nn.relu)\n",
        "        self.q_state = tf.layers.dense(self.hidden1, action_size, activation=None)\n",
        "        self.q_state_action = tf.reduce_sum(tf.multiply(self.q_state, action_one_hot), axis=1)\n",
        "        \n",
        "        self.loss = tf.reduce_mean(tf.square(self.q_state_action - self.q_target_in))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.loss)\n",
        "        \n",
        "    def update_model(self, session, state, action, q_target):\n",
        "        feed = {self.state_in: state, self.action_in: action, self.q_target_in: q_target}\n",
        "        session.run(self.optimizer, feed_dict=feed)\n",
        "        \n",
        "    def get_q_state(self, session, state):\n",
        "        q_state = session.run(self.q_state, feed_dict={self.state_in: state})\n",
        "        return q_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi1EOSklJXTK"
      },
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, maxlen):\n",
        "        self.buffer = deque(maxlen=maxlen)\n",
        "        \n",
        "    def add(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "        \n",
        "    def sample(self, batch_size):\n",
        "        sample_size = min(len(self.buffer), batch_size)\n",
        "        samples = random.choices(self.buffer, k=sample_size)\n",
        "        return map(list, zip(*samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp8Nmg1iJZwP"
      },
      "source": [
        "class DQNAgent():\n",
        "    def __init__(self, env):\n",
        "        self.state_dim = env.observation_space.shape\n",
        "        self.action_size = env.action_space.n\n",
        "        self.q_network = QNetwork(self.state_dim, self.action_size)\n",
        "        self.replay_buffer = ReplayBuffer(maxlen=10000)\n",
        "        self.gamma = 0.97\n",
        "        self.eps = 1.0\n",
        "        \n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        \n",
        "    def get_action(self, state):\n",
        "        q_state = self.q_network.get_q_state(self.sess, [state])\n",
        "        action_greedy = np.argmax(q_state)\n",
        "        action_random = np.random.randint(self.action_size)\n",
        "        action = action_random if random.random() < self.eps else action_greedy\n",
        "        return action\n",
        "    \n",
        "    def train(self, state, action, next_state, reward, done):\n",
        "        self.replay_buffer.add((state, action, next_state, reward, done))\n",
        "        states, actions, next_states, rewards, dones = self.replay_buffer.sample(50)\n",
        "        q_next_states = self.q_network.get_q_state(self.sess, next_states)\n",
        "        q_next_states[dones] = np.zeros([self.action_size])\n",
        "        q_targets = rewards + self.gamma * np.max(q_next_states, axis=1)\n",
        "        self.q_network.update_model(self.sess, states, actions, q_targets)\n",
        "        \n",
        "        if done: self.eps = max(0.1, 0.99*self.eps)\n",
        "    \n",
        "    def __del__(self):\n",
        "        self.sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2l_QbEJdP5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "3353b843-562c-45f9-809e-257ee00bb4d1"
      },
      "source": [
        "agent = DQNAgent(env)\n",
        "num_episodes = 100\n",
        "\n",
        "for ep in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = agent.get_action(state)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        agent.train(state, action, next_state, reward, done)\n",
        "        env.render()\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "        \n",
        "    print(\"Episode: {}, total_reward: {:.2f}\".format(ep, total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-aabc529be209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_before_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitoring/stats_recorder.py\u001b[0m in \u001b[0;36mbefore_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "B6bzWrSVL_hs",
        "outputId": "4c191958-aba5-4041-d3cd-f4736c80080e"
      },
      "source": [
        "\n",
        "state = env.reset()\n",
        "\n",
        "while True:\n",
        "    action = agent.get_action(state)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "    if done:\n",
        "      break\n",
        "  \n",
        "env.close()\n",
        "show_video()    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0f04697d5207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_before_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitoring/stats_recorder.py\u001b[0m in \u001b[0;36mbefore_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDGW5vDYMBBz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}